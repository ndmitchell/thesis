%include paper.fmt

%format target = "\textsc{target}"
%format unit = "\textsc{unit}"
%format |- = "\mathbin{\vdash}"
%format |+ = "\mathsf{\hspace{1mm}|\hspace{-0.5mm}\hbox{\small{+}}\;}"
%format |* = "\mathsf{\hspace{1mm}|\hspace{-0.65mm}*\;}"
%format ||* = "\mathsf{\hspace{1mm}||\hspace{-0.65mm}*\;}"
%format ||+ = "\mathsf{\hspace{1mm}||\hspace{-0.5mm}\hbox{\small{+}}\;}"


\begin{comment}
% extra code needed for tex2hs
\begin{code}
class Uniplate x where
	uniplate :: x -> ([x], [x] -> x)
\end{code}
\begin{code}
class Uniplate x where
\end{code}
\begin{code}
transform' x = transform x
\end{code}
\begin{code}
children = undefined
context = undefined
\end{code}
\end{comment}


\chapter{Boilerplate Removal}
\label{chp:uniplate}

\todo{Koen's extensions to use a Tree type}

Generic traversals over recursive data structures are often referred to as \textit{boilerplate} code. This chapter describes the Uniplate library, which offers a way to abstract several common forms of boilerplate code. \S\ref{secU:intro} gives an example problem, and our solution. \S\ref{secU:use_play} introduces the traversal combinators that we propose, along with short examples. \S\ref{secU:implement_play} discusses how these combinators are implemented in terms of a single primitive. \S\ref{secU:use_playex} extends this approach to multi-type traversals, and \S\ref{secU:implement_playex} covers the extended implementation. \S\ref{secU:performance} investigates some performance optimisations. \S\ref{secU:results} gives comparisons with other approaches, using examples such as the ``paradise'' benchmark. \S\ref{secU:related} presents related work.


\section{Introductory Example}
\label{secU:intro}

Take a simple example of a recursive data type:

\begin{code}
data Expr  =  Add  Expr  Expr  |  Val  Int
           |  Sub  Expr  Expr  |  Var  String
           |  Mul  Expr  Expr  |  Neg  Expr
           |  Div  Expr  Expr
\end{code}

The |Expr| type represents a small language for integer expressions, which permits free variables. Suppose we need to extract a list of all the variable occurrences in an expression:

\begin{code}
variables :: Expr -> [String]
variables (Var  x    ) = [x]
variables (Val  x    ) = []
variables (Neg  x    ) = variables x
variables (Add  x y  ) = variables x ++ variables y
variables (Sub  x y  ) = variables x ++ variables y
variables (Mul  x y  ) = variables x ++ variables y
variables (Div  x y  ) = variables x ++ variables y
\end{code}

This definition has the following undesirable characteristics: (1) adding a new constructor would require an additional equation; (2) the code is repetitive, the last four right-hand sides are identical; (3) the code cannot be shared with other similar operations. This problem is referred to as the \textit{boilerplate} problem. Using the Uniplate library, the above example can be rewritten as:

\begin{code}
variables :: Expr -> [String]
variables x = [y | Var y <- universe x]
\end{code}

The type signature is optional, and would be inferred automatically if left absent. This example assumes a |Uniplate| instance for the |Expr| data type, given in \S\ref{secU:play_instances}. This example requires only Haskell 98. For more advanced examples we require multi-parameter type classes -- but no functional dependencies, rank-2 types or GADTs.

The central idea is to exploit a common property of many traversals: they only require value-specific behaviour for a \textit{single uniform type}. In the |variables| example, the only type of interest is |Expr|. In practical applications, this pattern is common\footnote{Most examples in boilerplate removal papers meet this restriction, even though the systems being discussed do not depend on it.}. By focusing only on uniform type traversals, we are able to exploit well-developed techniques in list processing.

\subsection{Contribution}

Ours is far from the first technique for `scrapping boilerplate'. The area has been researched extensively. But there are a number of distinctive features in our approach:

\begin{itemize}
\item We require \textit{no language extensions} for single-type traversals, and only multi-parameter type classes \citep{jones:mptc} for multi-type traversals.
\item Our \textit{choice of operations} is new: we shun some traditionally provided operations, and provide some uncommon ones.
\item Our type classes can be defined independently \textit{or} on top of |Typeable| and |Data| \citep{lammel:syb}, making \textit{optional use of built-in compiler support}.
\item We make use of \textit{list-comprehensions} \citep{wadler:list_comprehensions} for succinct queries.
\item We \textit{compare the conciseness} of operations using our library, by counting lexemes, showing our approach leads to less boilerplate.
\item We \textit{compare the performance} of traversal mechanisms, something that has been neglected in previous papers.
\end{itemize}

\section{Queries and Transformations}
\label{secU:use_play}

We define various traversals, using the |Expr| type defined in the introduction as an example throughout. We divide \textit{traversals} into two categories: queries and transformations. A \textit{query} is a function that takes a value, and extracts some information of a different type. A \textit{transformation} takes a value, and returns a modified version of the original value. All the traversals rely on the class |Uniplate|, an instance of which is assumed for |Expr|. The definition of this class and its instances are covered in \S\ref{secU:implement_play}.

\subsection{Children}

The first function in the Uniplate library serves as both a function, and a definition of terminology:

\begin{code}
children :: Uniplate alpha => alpha -> [alpha]
\end{code}

The function |children| takes a value and returns \textit{all maximal proper substructures of the same type}. For example:

\begin{code}
children (Add (Neg (Var "x")) (Val 12)) = [Neg (Var "x"), Val 12]
\end{code}

The |children| function is occasionally useful, but is used more commonly as an auxiliary in the definition of other functions.


\subsection{Queries}

The Uniplate library provides a the |universe| function to support queries.

\begin{code}
universe :: Uniplate alpha => alpha -> [alpha]
\end{code}

This function takes a data structure, and returns a list of \textit{all} structures of the same type found within it. For example:

\begin{code}
universe (Add (Neg (Var "x")) (Val 12)) =
    [Add (Neg (Var "x")) (Val 12)
    ,Neg (Var "x")
    ,Var "x"
    ,Val 12]
\end{code}

One use of this mechanism for querying was given in the introduction. Using the |universe| function, queries can be expressed very concisely. Using a list-comprehension to process the results of |universe| is common.

\begin{example}
\label{exU:zerocount}
Consider the task of counting divisions by the literal 0.

\begin{code}
countDivZero :: Expr -> Int
countDivZero x = length [() | Div _ (Val 0) <- universe x]
\end{code}

Here we make essential use of a feature of list comprehensions: if a pattern does not match, then the item is skipped. In other syntactic constructs, failing to match a pattern results in a pattern-match error.
\end{example}

\subsection{Bottom-up Transformations}

Another common operation provided by many boilerplate removal systems \citep{lammel:syb,stratego,strafunski,ren:generic_recursion_toolbox} applies a given function to every subtree of the argument type. We define as standard a bottom-up transformation.

\begin{code}
transform :: Uniplate alpha => (alpha -> alpha) -> alpha -> alpha
\end{code}

The result of |transform f x| is |f x'| where |x'| is obtained by replacing each |alpha|-child |x_i| in |x| by |transform f x_i|.

\begin{example}
\label{exU:simplify}
Suppose we wish to remove the |Sub| constructor assuming the equivalence: |x - y == x + (- y)|. To apply this equivalence as a rewriting rule, at all possible places in an expression, we define:

\begin{code}
simplify x = transform f x
    where  f (Sub x y)  = Add x (Neg y)
           f x          = x
\end{code}

This code can be read: apply the subtraction rule where you can, and where you cannot, do nothing. Adding additional rules is easy. Take for example: \ignore|x + y = 2 * x where x == y|. Now we can add this new rule into our existing transformation:

\begin{code}
simplify x = transform f x
    where  f (Sub x y)           = Add x (Neg y)
           f (Add x y) | x == y  = Mul (Val 2) x
           f x                   = x
\end{code}

Each equation corresponds to the natural Haskell translation of the rule. The |transform| function manages all the required boilerplate.
\end{example}

\subsection{Top-Down Transformation}

The Scrap Your Boilerplate approach \cite{lammel:syb} (known as SYB) provides a top-down transformation named |everywhere'|. We describe this traversal, and our reasons for \textit{not} providing it, even though it could easily be defined. We instead provide |descend|, based on the |composOp| operator \cite{bringert:compos}.

The |everywhere' f| transformation applies |f| to a value, then recursively applies the transformation on all the children of the freshly generated value. Typically, the intention in a transformation is to apply |f| to \textit{every node exactly once}. Unfortunately, |everywhere' f| does not necessarily have this effect.

\begin{example}
Consider the following transformation:

\begin{code}
doubleNeg (Neg (Neg x))  = x
doubleNeg x              = x
\end{code}

The intention is clear: remove all instances of double negation. When applied in a bottom-up manner, this is the result. But when applied top-down some nodes are missed. Consider the value |Neg (Neg (Neg (Neg (Val 1))))|; only the outermost double negation will be removed.
\end{example}

\begin{example}
Consider the following transformation:

\begin{code}
reciprocal (Div n m)  = Mul n (Div (Val 1) m)
reciprocal x          = x
\end{code}

This transformation removes arbitrary division, converting it to divisions where the numerator is always 1. If applied once to each subtree, this computation would terminate successfully. Unfortunately, top-down transformation treats the generated |Mul| as  being transformed, but cannot tell that the generated |Div| is the result of a transformation, not a fragment of the original input. This leads to a non-termination error.
\end{example}

As these examples show, when defining top-down transformations using |everywhere'| it is easy to slip up. The problem is that the program cannot tell the difference between freshly created constructors, and values that come originally from the input.

So we do support top-down transformations, but require the programmer to make the transformation more explicit. We introduce the |descend| function, inspired by the Compos paper \cite{bringert:compos}.

\begin{code}
descend :: Uniplate alpha => (alpha -> alpha) -> alpha -> alpha
\end{code}

The result of |descend f x| is obtained by replacing each |alpha|-child |x_i| in |x| by |f x_i|. Unlike |everywhere'|, there is \textit{no recursion} within |descend|.

\begin{comment}
\begin{code}
data Expr = Var String | Let String Expr Expr | Add Expr Expr
\end{code}
\end{comment}

\begin{example}
Consider the addition of a constructor \ignore|Let String Expr Expr|. Now let us define a function |subst| to replace free variables with given expressions. In order to determine which variables are free, we need to ``remember'' variables that are bound as we descend\footnote{For simplicity, we ignore issues of hygienic substitution that may arise if substituted expressions themselves contain free variables.}. We can define |subst| using a descend transformation:

\begin{code}
subst :: [(String,Expr)] -> Expr -> Expr
subst rep x =
    case  x of
          Let name bind x -> Let name (subst rep bind)
              (subst (filter ((/= name) . fst) rep) x)
          Var x -> fromMaybe (Var x) (lookup x rep)
          _ -> descend (subst rep) x
\end{code}

The |Var| alternative may return an |Expr| from |rep|, but no additional transformation is performed on this value, since all transformation is made explicit. In the |Let| alternative we explicitly continue the |subst| transformation.
\end{example}

\subsection{Transformations to a Normal Form}

In addition to top-down and bottom-up transformations, we also provide transformations to a normal form. The idea is that a rule is applied exhaustively until a normal form is achieved. Consider a rewrite transformation:

\begin{code}
rewrite :: Uniplate alpha => (alpha -> Maybe alpha) -> alpha -> alpha
\end{code}

A rewrite-rule argument |r| takes an expression |e| of type |alpha|, and returns either |Nothing| to indicate that the rule is not applicable, or |Just e'| indicating that |e| is rewritten by |r| to |e'|. The intuition for |rewrite r| is that it applies |r| exhaustively; a postcondition for |rewrite| is that there must be no places where |r| could be applied. That is, the following property must hold:

\begin{code}
propRewrite r x = all (isNothing . r) (universe (rewrite r x))
\end{code}

One way to define the |rewrite| function uses |transform|:

\begin{code}
rewrite :: Uniplate alpha => (alpha -> Maybe alpha) -> alpha -> alpha
rewrite f = transform g
    where g x = maybe x (rewrite f) (f x)
\end{code}

This definition tries to apply the rule everywhere in a bottom-up manner. If at any point it makes a change, then the new value has the rewrite applied to it. The function only terminates when a normal form is reached.

A disadvantage of |rewrite| is that it may check unchanged sub-expressions repeatedly. Performance sensitive programmers might prefer to use an explicit transformation, and manage the rewriting themselves. We show under which circumstances a bottom-up transformation obtains a normal form, and how any transformation can be modified to ensure a normal form.

\subsubsection{Bottom-Up Transformations to a Normal Form}
\label{secU:rewrite_bottom}

We define the function |always| that takes a rewrite rule |r| and produces a function appropriate for use with |transform|.

\begin{code}
always :: (alpha -> Maybe alpha) -> (alpha -> alpha)
always r x = fromMaybe x (r x)
\end{code}

What restrictions on |r| ensure that the property \ignore|rewrite r x == transform (always r) x| holds? It is sufficient that the constructors on the right-hand side of |r| do not overlap with the constructors on the left-hand side.

\begin{examplerevisit}{\ref{exU:simplify}}

Recall the |simplify| transformation, as a rewrite:

\begin{code}
r (Sub x y)           = Just $ Add x (Neg y)
r (Add x y) | x == y  = Just $ Mul (Val 2) x
r _                   = Nothing
\end{code}

Here |Add| occurs on the right-hand side of the first line, and on the left-hand side of the second. From this we can construct a value where the two alternatives differ:

\ignore\begin{code}
let x = Sub (Neg (Var "q")) (Var "q")

rewrite    r           x == Mul (Val 2) (Neg (Var "q"))
transform  (always r)  x == Add (Neg (Var "q")) (Neg (Var "q"))
\end{code}

To remedy this situation in the original |simplify| transformation, whenever the right-hand side introduces a new constructor, |f| may need to be reapplied. Here only one additional |f| application is necessary, the one attached to the construction of an |Add| value.

\begin{code}
f (Sub x y)           = f $ Add x (Neg y)
f (Add x y) | x == y  = Mul (Val 2) x
f x                   = x
\end{code}\codeexample
\end{examplerevisit}


\subsection{Action Transformations}

Rewrite transformations apply a set of rules \textit{repeatedly} until a normal form is found. One alternative is an action transformation, where each node is visited and transformed \textit{once}, and state is maintained and updated as the operation proceeds. The standard technique is to thread a monad through the operation, which we do using |transformM|.

\begin{example}
Suppose we wish to rename each variable to be unique:

\begin{code}
uniqueVars :: Expr -> Expr
uniqueVars x = evalState (transformM f x) vars
    where
        vars = ['x':show i | i <- [1..]]

        f (Var i)  = do  y:ys <- get
                         put ys
                         return (Var y)
        f x        = return x
\end{code}

The function |transformM| is a monadic variant of |transform|. Here a \textit{state monad} is used to keep track of the list of names not yet used, with |evalState| computing the result of the monadic action, given an initial state |vars|.
\end{example}

\subsection{Paramorphisms}

A paramorphism is a fold in which the recursive step may refer to the recursive component of a value, not just the results of folding over them \cite{meertens:paramorphisms}. We define a similar recursion scheme in our library.

\begin{code}
para :: Uniplate alpha => (alpha -> [r] -> r) -> alpha -> r
\end{code}

The |para| function uses the functional argument to combine a value, and the results of |para| on its children, into a new result.

\begin{example}
Compiler writers might wish to compute the \textit{depth of expressions}:

\begin{code}
depth :: Expr -> Int
depth = para (\_ cs -> 1 + maximum (0:cs))
\end{code}\codeexample
\end{example}

\subsection{Contexts}

The final operation in the library seems to be a novelty -- we have not seen it in any other generics library, even in those which attempt to include all variations \citep{ren:generic_recursion_toolbox}. This operation is similar to contextual pattern matching \citep{mohnen:context_patterns}.\footnote{This function was contributed by Eric Mertens.}

\begin{code}
contexts :: Uniplate alpha => alpha -> [(alpha, alpha -> alpha)]
\end{code}

This function returns lists of pairs |(x,f)| where |x| is an element of the data structure which would have been returned by |universe|, and |f| replaces the hole which |x| was removed from.

\begin{example}
Suppose that mutation testing requires all expressions obtained by incrementing or decrementing \textit{any single} literal in an original expression.

\begin{code}
mutants :: Expr -> [Expr]
mutants x =  [c (Val j) | (Val i, c) <- contexts x,  j <- [i-1, i+1]]
\end{code}
\end{example}

In general, |contexts| has the following properties:

\begin{code}
propUniverse  x = universe x == map fst (contexts x)
propId        x = all (== x) [b a | (a,b) <- contexts x]
\end{code}



\subsection{Summary}

\begin{figure}
\begin{code}
module Data.Generics.Uniplate where

children    :: Uniplate alpha => alpha -> [alpha]
contexts    :: Uniplate alpha => alpha -> [(alpha, alpha -> alpha)]
descend     :: Uniplate alpha => (alpha -> alpha) -> alpha -> alpha
descendM    :: (Uniplate alpha, Monad m) => (alpha -> m alpha) -> alpha -> m alpha
para        :: Uniplate alpha => (alpha -> [r] -> r) -> alpha -> r
rewrite     :: Uniplate alpha => (alpha -> Maybe alpha) -> alpha -> alpha
rewriteM    :: (Uniplate alpha, Monad m)  => (alpha -> m (Maybe alpha)) -> alpha -> m alpha
transform   :: Uniplate alpha => (alpha -> alpha) -> alpha -> alpha
transformM  :: (Uniplate alpha, Monad m) => (alpha -> m alpha) -> alpha -> m alpha
universe    :: Uniplate alpha => alpha -> [alpha]
\end{code}
\caption{All |Uniplate| methods.}
\label{figU:play}
\end{figure}

We present signatures for all our methods in Figure \ref{figU:play}, including several monadic variants. In our experience, the most commonly used operations are |universe| and |transform|, followed by |transformM| and |descend|.


\section{Implementing the |Uniplate| class}
\label{secU:implement_play}

Requiring each instance of the |Uniplate| class to implement ten separate methods would be an undue imposition. Instead, given a type specific instance for a \textit{single} auxiliary method with a pair as result, we can define \textit{all ten} operations generically, at the class level. The auxiliary is:

\begin{code}
uniplate :: Uniplate alpha => alpha -> ([alpha], [alpha] -> alpha)
uniplate x = (children,context)
\end{code}

The |children| are all the maximal proper substructures of the same type as |x|; the |context| is a function to generate a new value, with a different set of children. The caller of |context| must ensure that the length of the list given to |context| is the same as the length of |children|. The result pair splits the information in the value, but by combining the |context| with the |children| the original value can be recovered:

\begin{code}
propId x = x == context children
    where (children,context) = uniplate x
\end{code}

\subsection{Operations in terms of |uniplate|}
\label{secU:using_replacechildren}

All ten operations of \S\ref{secU:use_play} can be defined in terms of |uniplate| very concisely. We define four functions as examples.

\begin{code}
children :: Uniplate alpha => alpha -> [alpha]
children = fst . uniplate

universe :: Uniplate alpha => alpha -> [alpha]
universe x = x : concatMap universe (children x)

transform :: Uniplate alpha => (alpha -> alpha) -> alpha -> alpha
transform f x = f $ context $ map (transform f) children
    where (children, context) = uniplate x

descend :: Uniplate alpha => (alpha -> alpha) -> alpha -> alpha
descend f x = context $ map f children
    where (children, context) = uniplate x
\end{code}

The common pattern is to call |uniplate|, then operate on the current children, often calling |context| to create a modified value. Some of these definitions can be made more efficient -- see \S\ref{secU:optimise_everything}.

\subsection{Writing |Uniplate| instances}
\label{secU:play_instances}

\begin{figure}
\begin{code}
class Uniplate alpha where
    uniplate :: alpha -> ([alpha], [alpha] -> alpha)

instance Uniplate Expr where
    uniplate (Neg  a    )  = ([a]    , \[a']     -> Neg  a'     )
    uniplate (Add  a b  )  = ([a,b]  , \[a',b']  -> Add  a' b'  )
    uniplate (Sub  a b  )  = ([a,b]  , \[a',b']  -> Sub  a' b'  )
    uniplate (Mul  a b  )  = ([a,b]  , \[a',b']  -> Mul  a' b'  )
    uniplate (Div  a b  )  = ([a,b]  , \[a',b']  -> Div  a' b'  )
    uniplate x             = ([]     , \[]       -> x           )
\end{code}
\caption{The |Uniplate| class and an instance for |Expr|.}
\label{figU:play_expr}
\end{figure}

We define a |Uniplate| instance for the |Expr| type in Figure \ref{figU:play_expr}.

The distinguishing feature of our library is that the children are defined in terms of their type. While this feature keeps the traversals simple, it does mean that rules for \textit{deriving} instance definitions are not purely syntactic, but depend on the types of the constructors. We now describe the derivation rules, followed by information on the Derive tool that performs this task automatically. (If we are willing to make use of Multi-Parameter Type Classes, simpler derivation rules can be used: see \S\ref{secU:implement_playex}.)


\subsection{Derivation Rules}

We can define derivation rules for the |children| and |context| functions, allowing the definition:

\ignore\begin{code}
instance Uniplate Type where
    uniplate x = (children x, context x)
\end{code}

Alternatively, it is possible to define one single function which generates both elements of the pair at once, avoiding the need to examine each value twice (see \S\ref{secU:optimise_playdata} for an example).

We model the derivation of an instance by describing a derivation from a data type to a set of declarations. The derivation rules have three functional parameters: |(<>)|, |unit| and |target|. By varying these parameters we derive either |children| or |context| functions.

\begin{figure}
\ignore\begin{code}
_D $| data d v_1...v_n = a_1...a_m |$ =
        _N $| d |$ \? v_1...v_n x = case  x of _C $| a_1 |$ \? ... \? _C $| a_m |$
    where x {-" \mbox{ is fresh} "-}

_C $| c t_1...t_n |$ =
        c y_1...y_n -> unit c <> _T $| t_1 |$ \? y_1 <> ... <> _T $| t_n |$ \? y_n
    where y_1...y_n {-" \mbox{ are fresh} "-}

_T $| TargetType     |$ = target
_T $| PrimitiveType  |$ = unit
_T $| d t_1...t_n    |$ = _N $| d |$ \? _T $| t_1 |$ \? ... \? _T $| t_n |$
_T $| v              |$ = v

_N {-" \mbox{ is an injection to fresh variables} "-}
\end{code}
\caption{Derivation rules for Uniplate instances.}
\label{figU:derive}
\end{figure}

The derivation rules are given in Figure \ref{figU:derive}. The |_D| rule takes a data type declaration, and defines a function over that data type. The |_C| rule defines a case alternative for each constructor. The |_T| rule defines type specific behaviour: a type is either the target type on which an instance is being defined, or a primitive such as |Char|, or an algebraic data type, or a free type variable.

\begin{comment}

To model the derivation of an instance, it is necessary to have a model of data types:

\begin{code}
data Data  = Data  Name [Var] [Ctor]
data Ctor  = Ctor  Name [Type]
data Type  = TyPrim | TyVar Var | TyApp Data [Type]

type Name  = String
type Var   = String
\end{code}

\begin{code}
isTarget :: a -> Bool
\end{code}

When writing a |Uniplate| instance for a particular data type, |isTarget| returns True for that data type. We define how to produce a function for a given |Data| type using the |_D| function:

\begin{code}


unwords $
    ['d':name] ++ vars ++ ["x ="] ++
    ["case x of {"] ++
        separate ";" (map _C ctors) ++
    ["}"]

_C (Ctor name typs) =
    [name] ++ vars ++ [" -> "] ++
    ["unit"] ++ [name] ++ ["<>"] ++
    separate "<>" (zipWith (:) vars (map _T typs))
    where vars = ['v':show i | i <- [1..length typs]]

_T (TyPrim                       ) = ["unit"]
_T (TyVar  v                     ) = [v]
_T (TyApp  d@(Data name _ _) ts  )
    | isTarget d  = ["target"]
    | otherwise   = ['d':name] ++ concatMap _T ts

separate sep xs = concat $ intersperse [sep] xs
\end{code}

\end{comment}

Applying |_D| to |Expr|, the result is:

\begin{code}
_N $| Expr |$ \? x = case x of
    Val  y_1      -> unit Val  <> unit y_1
    Var  y_1      -> unit Var  <> _N $| List |$ \? unit y_1
    Neg  y_1      -> unit Neg  <> target y_1
    Add  y_1 y_2  -> unit Add  <> target y_1 <> target y_2
    Sub  y_1 y_2  -> unit Sub  <> target y_1 <> target y_2
    Mul  y_1 y_2  -> unit Mul  <> target y_1 <> target y_2
    Div  y_1 y_2  -> unit Div  <> target y_1 <> target y_2

_N $| List |$ \? v_1 x = case x of
    []            -> unit []
    (:)  y_1 y_2  -> unit (:) <> v_1 y_1 <> _N $| List |$ \? v_1 y_2
\end{code}

\begin{comment}
To generate a particular operation we can replace the |unit|, |target| and |<>| functions with versions specific to that operation. We do this replacement using multiple copies of the template, introducing |where| clauses with local definitions of the three functions.
\end{comment}

\subsubsection{Defining |children|}

To derive the |children| function, the derivations are applied with the following parameter values.

\begin{code}
unit    = const []
target  = (:[])
(<>)    = (++)

children x = _N $| Type |$ \? x
\end{code}

The generated function is a traversal which visits every value in the data type. A list is created of all the target types by placing the targets into lists, combining lists using |(++)|, and skipping uninteresting values.

From these definitions we can do some reasoning. For example, |list == concatMap|, and |concatMap (const []) == const []|. This information can be used to simplify some instances.

\subsubsection{Defining |context|}

For |context| functions we apply the derivation rules with the following parameter values.

\begin{code}
type Cont t alpha = [alpha] -> (t,[alpha])

unit :: t -> Cont t alpha
unit x ns = (x,ns)

target :: alpha -> Cont alpha alpha
target x (n:ns) = (n,ns)

(<>) :: Cont (a->b) alpha -> Cont a alpha -> Cont b alpha
(<>) a b ns_1 =  let  (a'  ,ns_2  ) = a  ns_1
                      (b'  ,ns_3  ) = b  ns_2
                 in   (a' b',ns_3)

context x ns = fst (_N $| Type |$ \? x ns)
\end{code}

The central |Cont| type is an extension to the type of |context| which takes a list of children to substitute into a value, and returns both the new value, and the children which were not used. By returning the unused children the |(<>)| operation is able to determine both the new value for |a| (namely |a'|), and the remaining list of children (namely |ns2|), sequencing the use of the children. The |target| function consumes a child, and the |unit| function returns the children unmodified.

\begin{comment}
It is possible to improve the simplification opportunities and runtime speed by moving to continuation passing.
, by redefining if we use a continuation function to encode the pair.

\begin{code}
setChildren x ns = dExpr x ns const

type Cont t alpha r = [alpha] -> (t -> [alpha] -> r) -> r

unit :: t -> Cont t alpha r
unit    x  ns      c  = c x ns

target :: alpha -> Cont alpha alpha r
target  x  (n:ns)  c  = c n ns

(<>) :: Cont (a->b) alpha r -> Cont a alpha r -> Cont b alpha r
(<>) a b ns c =  a  ns $ \a'  ns ->
                 b  ns $ \b'  ns ->
                 c (a' b') ns
\end{code}
\end{comment}

\subsection{Automated Derivation of |uniplate|}

Applying these derivation rules is a form of boilerplate coding! The DrIFT tool \citep{drift} derives instances automatically given rules depending only on the information contained in a type definition. However DrIFT is unable to operate with certain Haskell extensions ({\TeX} style literate Haskell, C pre processor), and requires a separate pre-processing stage.

In collaboration with Stefan O'Rear we have developed the Derive tool \citep{derive}. Derive is based on Template Haskell \citep{template_haskell} and has predefined rules for derivation of |Uniplate| instances. It has special rules to remove redundant patterns to produce simpler and more efficient instances.

\begin{example}
\begin{code}
data Term  =  Name String
           |  Apply Term [Term]
              deriving ( {-! \textsf{Uniplate} !-} )
\end{code}

Running the Derive tool over this file, the generated code is:

\begin{code}
instance Uniplate Term where
    uniplate (Name  x_1      ) = ([]       , \_       -> Name x_1     )
    uniplate (Apply x_1 x_2  ) = (x_1:x_2  , \(n:ns)  -> Apply n ns  )
\end{code}
\end{example}


\section{Multi-type Traversals}
\label{secU:use_playex}

We have introduced the |Uniplate| class and an instance of it for type |Expr|. Now let us imagine that |Expr| is merely the expression type in a language with statements:

\begin{onepage}
\begin{code}
data Stmt  =  Assign    String  Expr
           |  Sequence  [Stmt]
           |  If        Expr    Stmt Stmt
           |  While     Expr    Stmt
\end{code}
\end{onepage}

We could define a |Uniplate| instance for |Stmt|, and so perform traversals upon statements too. However, we may run into limitations. Consider the task of finding all literals in a |Stmt| -- this requires boilerplate to find not just inner statements of type |Stmt|, but inner expressions of type |Expr|.

The |Uniplate| class takes a value of type |alpha|, and operates on its substructures of type |alpha|. What we now require is something that takes a value of type |beta|, but operates on the children of type |alpha| within it -- we call this class |Biplate|. Typically the type |beta| will be a container of |alpha|. We can extend our operations by specifying how to find the |alpha|'s within the |beta|'s, and then perform the standard |Uniplate| operations upon the |alpha| type. In the above example, \ignore|alpha = Expr|, and \ignore|beta = Stmt|.

We first introduce |UniplateOn|, which requires an explicit function to find the occurrences of  type |alpha| within type |beta|. We then make use of Multi-parameter type classes (MPTC's) to generalise this function into a type class, named |Biplate|.

\subsection{The |UniplateOn| Operations}

We define operations, including |universeOn| and |transformOn|, which take an extra argument relative to the standard |Uniplate| operators. We call this extra argument |biplate|: it is a function from the containing type (|beta|) to the contained type (|alpha|).

\begin{comment}
\begin{code}
type BiplateType beta alpha = beta -> ([alpha], [alpha] -> beta)
\end{code}
\end{comment}

\begin{code}
type BiplateType beta alpha = beta -> ([alpha], [alpha] -> beta)
biplate :: BiplateType beta alpha
\end{code}

The intuition for |biplate| is that given a structure of type |beta|, the function should return the largest substructures in it of type |alpha|. If \ignore|alpha == beta| the original value should be returned:

\begin{code}
biplateSelf :: BiplateType alpha alpha
biplateSelf x = ([x], \[x'] -> x')
\end{code}

We can now define |universeOn| and |transformOn|. Each takes a |biplate| function as an argument:

\begin{code}
universeOn :: Uniplate alpha => BiplateType beta alpha -> beta -> [alpha]
universeOn biplate x = concatMap universe $ fst $ biplate x

transformOn  ::  Uniplate alpha => BiplateType beta alpha -> (alpha -> alpha) -> beta -> beta
transformOn biplate f x = context $ map (transform f) children
    where (children, context) = biplate x
\end{code}

These operations are similar to the original |universe| and |transform|. They unwrap |beta| values to find the |alpha| values within them, operate using the standard |Uniplate| operations for type |alpha|, then rewrap if necessary. If |alpha| is constant, there is another way to abstract away the |biplate| argument, as the following example shows.

\begin{example}
The Yhc.Core library \citep{me:yhc_core}, part of the York Haskell Compiler (Yhc), makes extensive use of |Uniplate|. In this library, the central types include:

\begin{comment}
\begin{code}
data CoreData = CoreData
\end{code}
\end{comment}

\begin{code}
data Core      =  Core String [String] [CoreData] [CoreFunc]

data CoreFunc  =  CoreFunc String String CoreExpr

data CoreExpr  =  CoreVar   String
               |  CoreApp   CoreExpr  [CoreExpr]
               |  CoreCase  CoreExpr  [(CoreExpr, CoreExpr)]
               |  CoreLet   [(String, CoreExpr)] CoreExpr
                  -- other constructors
\end{code}

Most traversals are performed on the |CoreExpr| type. However, it is often convenient to start from one of the other types. For example, |coreSimplify :: CoreExpr -> CoreExpr| may be applied not just to an individual expression, but to all expressions in a function definition, or a complete program. If we are willing to freeze the type of the second argument to |biplate| as |CoreExpr| we can write a class:

\begin{code}
class  UniplateExpr beta where
       uniplateExpr :: BiplateType beta CoreExpr

universeExpr   x = universeOn   uniplateExpr x
transformExpr  x = transformOn  uniplateExpr x

instance Uniplate CoreExpr
instance UniplateExpr Core
instance UniplateExpr CoreFunc
instance UniplateExpr CoreExpr
instance UniplateExpr beta => UniplateExpr [beta]
\end{code}\codeexample
\end{example}
\bigskip

This technique has been used in the Yhc compiler. The Yhc compiler is written in Haskell 98 to allow for bootstrapping, so only the standard single-parameter type classes are available.

\subsection{The |Biplate| class}

If we are willing to make use of \textit{multi-parameter type classes} \cite{jones:mptc} we can define a class |Biplate| with |biplate| as its sole method. We do not require functional dependencies.

\begin{code}
class  Uniplate alpha => Biplate beta alpha where
       biplate :: BiplateType beta alpha
\end{code}

We can now implement |universeBi| and |transformBi| in terms of their |On| counterparts:

\begin{code}
universeBi :: Biplate beta alpha => beta -> [alpha]
universeBi = universeOn biplate

transformBi :: Biplate beta alpha => (alpha -> alpha) -> beta -> beta
transformBi = transformOn biplate
\end{code}

In general the move to |Biplate| requires few code changes, merely the use of the new set of |Bi| functions. To illustrate we give generalisations of two examples from previous sections, implemented using |Biplate|. We extend the |variables| and |simplify| functions to work on |Expr|, |Stmt| or many other types.

\begin{exampleany}{from \S1 (revisited)}
\begin{code}
variables :: Biplate beta Expr => beta -> [String]
variables x = [y | Var y <- universeBi x]
\end{code}

The equation requires only one change: the addition of the |Bi| suffix to |universe|. In the type signature we replace |Expr| with \ignore|Biplate beta Expr => beta|. Instead of requiring the input to be an |Expr|, we merely require that from the input we know how to reach an |Expr|.
\end{exampleany}

\begin{examplerevisit}{\ref{exU:simplify}}
\begin{code}
simplify :: Biplate beta Expr => beta -> beta
simplify x = transformBi f x
    where  f (Sub x y)  = Add x (Neg y)
           f x          = x
\end{code}

In this redefinition we have again made a single change to the equation: the addition of |Bi| at the end of |transform|.
\end{examplerevisit}

\section{Implementing |Biplate|}
\label{secU:implement_playex}

The complicating feature of |biplate| is that when defining |Biplate| where \ignore|alpha == beta| the function does not descend to the children, but simply returns its argument. This ``same type'' restriction can be captured either using the type system, or using the |Typeable| class \cite{lammel:syb}. We present three methods for defining a |Biplate| instance -- offering a trade-off between performance, compatibility and volume of code.

\begin{enumerate}
\item Direct definition requires $O(n^2)$ instances, but offers the highest performance with the fewest extensions.
\item The |Typeable| class can be used, requiring $O(n)$ instances and no further Haskell extensions, but giving worse performance.
\item The |Data| class can be used, providing fully automatic instances with GHC, but requiring the use of rank-2 types, and giving the worst performance.
\end{enumerate}

All three methods can be fully automated using the Derive tool, and all provide a simplified method for writing |Uniplate| instances. The first two methods require the user to define instances of auxiliary classes, |PlateAll| and |PlateOne|, on top of which the library defines the |Uniplate| and |Biplate| classes. The |Biplate| class definition itself is independent of the method used to implement its instances. This abstraction allows the user to start with the simplest instance scheme available to them, then move to alternative schemes to gain increased performance or compatibility.


\subsection{Direct instances}
\label{secU:implement_playdirect}

Writing direct instances requires the |Data.Generics.PlateDirect| module to be imported. This style requires a maximum of $n^2$ instance definitions, where $n$ is the number of types which contain each other, but gives the highest performance and most type-safety. The instances still depend on the type of each field, but are easier to define than the |Uniplate| instance discussed in \S\ref{secU:play_instances}. Here is a possible instance for the |Expr| type:

\begin{comment}
\begin{code}
class PlateAll from to where
    plateAll :: from -> Type from to
class PlateOne to where
    plateOne :: to -> Type to to
type Type from to = ([to] -> [to], [to] -> (from,[to]))
plate :: from -> Type from to
(|*) :: Type (to -> from) to -> to -> Type from to
(|+) :: PlateAll item to => Type (item -> from) to -> item -> Type from to
(|-) :: Type (item -> from) to -> item -> Type from to
(||*) :: Type ([to] -> from) to -> [to] -> Type from to
(||+) :: PlateAll item to => Type ([item] -> from) to -> [item] -> Type from to
\end{code}
\end{comment}

\begin{code}
instance PlateOne Expr where
    plateOne (Neg  a    )  = plate Neg  |* a
    plateOne (Add  a b  )  = plate Add  |* a |* b
    plateOne (Sub  a b  )  = plate Sub  |* a |* b
    plateOne (Mul  a b  )  = plate Mul  |* a |* b
    plateOne (Div  a b  )  = plate Div  |* a |* b
    plateOne x             = plate x
\end{code}

Five infix combinators (| ||*|, | ||+|, | ||-|, | ||||*| and | ||||+|) indicate the structure of the field to the right. The | ||*| combinator says that the value on the right is of the target type, | ||+| says that a value of the target type \textit{may occur} in the right operand, | ||-| says that values of the target type \textit{cannot occur} in the right operand. | ||||*| and | ||||+| are versions of | ||*| and | ||+| used when the value to the right is a \textit{list} either of the target type, or of a type that may contain target values. The law |plate f ||- x == plate (f x)| justifies the definition presented above.

This style of definition naturally expands to the multi-type traversal. For example:

\begin{code}
instance PlateAll Stmt Expr where
    plateAll (Assign    a b    ) = plate Assign    |-   a |*  b
    plateAll (Sequence  a      ) = plate Sequence  ||+  a
    plateAll (If        a b c  ) = plate If        |*   a |+  b |+ c
    plateAll (While     a b    ) = plate While     |*   a |+  b
\end{code}

From the definitions of |PlateOne| and |PlateAll| the library can define |Uniplate| and |Biplate| instances. The information provided by uses of | ||-| and | ||+| avoids redundant exploration down branches that do not have the target type. The use of | ||||*| is an optimisation which allows a list of the target type to be directly manipulated with |biplate| instead of producing and consuming this list twice. The use of | ||||+| avoids the definition of additional instances.

In the worst case, this approach requires an instance for each container/contained pair. In reality few traversal pairs are actually needed. The restricted pairing of types in |Biplate| instances also gives increased type safety; instances such as \ignore|Biplate Expr Stmt| do not exist.

In our experience definitions using these combinators offer similar performance to hand-tuned instances; see \S\ref{secU:results_speed} for measurements.


\subsection{|Typeable| based instances}
\label{secU:implement_playtypeable}

Instead of writing $O(n^2)$ class instances to locate values of the target type, we can use the |Typeable| class to \textit{test at runtime} whether we have reached the target type. We present derivations much as before, based this time only on combinators | ||+| and | ||-|:

\begin{comment}
\begin{code}
type Type from to = ([to] -> [to], [to] -> (from,[to]))
uniplateAll :: PlateAll a b => a -> ([b],[b] -> a)
class PlateAll from to where
    plateAll :: from -> Type from to
plate :: from -> Type from to
(|+) :: (Typeable item, Typeable to, PlateAll item to) => Type (item -> from) to -> item -> Type from to
(|-) :: Type (item -> from) to -> item -> Type from to
instance (PlateAll from to, Typeable from, Typeable to, Uniplate to) => PlateAll [from] to where
\end{code}
\end{comment}

\begin{code}
instance (Typeable alpha, Uniplate alpha) => PlateAll Expr alpha where
    plateAll (Neg a    )  = plate Neg  |+ a
    plateAll (Add a b  )  = plate Add  |+ a |+ b
    plateAll (Sub a b  )  = plate Sub  |+ a |+ b
    plateAll (Mul a b  )  = plate Mul  |+ a |+ b
    plateAll (Div a b  )  = plate Div  |+ a |+ b
    plateAll _            = plate x

instance (Typeable alpha, Uniplate alpha) => PlateAll Stmt alpha where
    plateAll (Assign    a b    ) = plate Assign    |-  a |+ b
    plateAll (Sequence  a      ) = plate Sequence  |+  a
    plateAll (If        a b c  ) = plate If        |+  a |+ b |+ c
    plateAll (While     a b    ) = plate While     |+  a |+ b
\end{code}

The | ||+| combinator is the most common, denoting that the value on the right may be of the target type, or may contain values of the target type. However, if we were to use | ||+| when the right-hand value was an |Int|, or other primitive type we did not wish to examine, we would require a |PlateAll| definition for |Int|. To omit these unnecessary instances, we can use | ||-| to indicate that the type is not of interest.

The |Data.Generics.PlateTypeable| module is able to automatically infer |Biplate| instances given a |PlateAll| instance. Alas this is not the case for |Uniplate|. Instead we must explicitly declare:

\begin{code}
instance Uniplate Expr where
    uniplate = uniplateAll

instance Uniplate Stmt where
    uniplate = uniplateAll
\end{code}

The reader may wonder why we cannot define:

\begin{code}
instance PlateAll alpha alpha => Uniplate alpha where
    uniplate = uniplateAll
\end{code}

Consider the |Expr| type. To infer \ignore|Uniplate Expr| we require an instance for \ignore|PlateAll Expr Expr|. But to infer this instance we require \ignore|Uniplate Expr| -- which we are in the process of inferring! \footnote{GHC has co-inductive or recursive dictionaries, but Hugs does not. To allow continuing compatibility with Hugs, and the use of fewer extensions, we require the user to write these explicitly for each type.}


\subsection{Using the |Data| class}
\label{secU:implement_playdata}

The existing |Data| and |Typeable| instances provided by the SYB approach can also be used to define |Uniplate| instances:

\ignore\begin{code}
import Data.Generics
import Data.Generics.PlateData

data Expr  = ... \? \? deriving (Typeable, Data)
data Stmt  = ... \? \? deriving (Typeable, Data)
\end{code}

The disadvantages of this approach are (1) \textit{lack of type safety} -- there are now |Biplate| instances for many pairs of types where one is not a container of the other; (2) \textit{compiler dependence} -- it will only work where |Data.Generics| is supported, namely GHC at the time of writing.\footnote{Hugs supports the required rank-2 types for |Data.Generics|, but the work to port the library has not been done yet.} The clear advantage is that there is almost no work required to create instances.

\begin{figure}
\ignore\begin{code}
repChildren  :: (Data alpha, Uniplate beta, Typeable alpha, Typeable beta)
             => alpha -> ([beta],[beta] -> alpha)
repChildren x = (children, context)
    where
        children = concat $ gmapQ (fst . biplate) x

        context xs = evalState (gmapM f x) xs
        f y = do  let (cs,con) = biplate y
                  (as,bs) <- liftM (splitAt $ length cs) get
                  put bs
                  return $ con as
\end{code}
\caption{Code for |Uniplate| in terms of |Data|.}
\label{figU:playdata}
\end{figure}

How do we implement the Uniplate class instances? The fundamental operation is given in Figure \ref{figU:playdata}. The \ignore|repChildren| function descends to each of the child nodes, and is guarded by a |Typeable| cast to ensure that \ignore|alpha /= beta|. The operation to get the children can be done using |gmapQ|. The operation to replace the children is more complex, requiring a state monad to keep track of the items to insert.

The code in Figure \ref{figU:playdata} is not optimised for speed. Uses of |splitAt| and |length| require the list of children to be traversed multiple times. We discuss improvements in \S\ref{secU:optimise_playdata}.


\section{Performance Improvements}
\label{secU:performance}

This section describes some of the performance improvements we have been able to make. First we focus on our optimisation of |universe|, using continuation passing and some |foldr|/|build| fusion properties \cite{spj:rules}. Next we turn to our |Data| class based instances, improving them enough to outperform SYB itself.

\subsection{Optimising the |universe| function}
\label{secU:optimise_everything}

Our initial |universe| implementation was presented in \S\ref{secU:using_replacechildren} as:

\begin{code}
universe :: Uniplate on => on -> [on]
universe x = x : concatMap universe (children x)
\end{code}

A disadvantage is that |concatMap| produces and consumes a list at every level in the data structure. We can fix this by using continuations:

\begin{code}
universe x = f x []
    where  f :: Uniplate on => on -> [on] -> [on]
           f x rest = x : concatCont (map f $ children x) rest

concatCont []     rest  =  rest
concatCont (x:xs) rest  =  x (concatCont xs rest)
\end{code}

Now we only perform one reconstruction. We can do even better using GHC's list fusion \cite{spj:rules}. The user of |universe| is often a list comprehension, which is a \textit{good consumer}. We can make |concatCont| a good consumer, and |f| a \textit{good producer}:

\begin{code}
universe :: Uniplate on => on -> [on]
universe x = build (f x)
    where
    f :: Uniplate on => on -> (on -> res -> res) -> res -> res
    f x cons nil = x `cons`
        concatCont (map (flip f cons) $ children x) nil

concatCont xs rest = foldr ($) rest xs
\end{code}

\subsection{Optimising |PlateData|}
\label{secU:optimise_playdata}

Surprisingly, it is possible to layer |Uniplate| over the |Data| instances of SYB, with better performance than SYB itself. The first optimisation is to generate the two members of the |uniplate| pair with only one pass over the data value. We cannot use SYB's |gmapM| or |gmapQ| -- we must instead use |gfoldl| directly. We also make use of continuation passing style in some places.

With this first improvement in place we perform much the same operations as SYB. But the overhead of list creation in |uniplate| makes traversals about 15\% slower than SYB.

The next optimisation relies on the extra information present in the |Uniplate| operations -- namely the target type. A boilerplate operation walks over a data structure, looking for target values to process. In SYB, the target values may be of \textit{any} type. For Uniplate the target is a \textit{single uniform} type. If a value is reached which is not a container for the target type, no further exploration is required of the values children. Computing which types are containers for the target type can be done relatively easily in the SYB framework \citep{lammel:syb2}:

\ignore\begin{code}
data DataBox = forall alpha `o` (Typeable alpha, Data alpha) => DataBox alpha

contains :: (Data alpha, Typeable alpha) => alpha -> [DataBox]
contains x = if isAlgType dtyp then concatMap f ctrs else []
    where
        f c = gmapQ DataBox (asTypeOf (fromConstr c) x)
        ctrs = dataTypeConstrs dtyp
        dtyp = dataTypeOf x
\end{code}

The \ignore|contains| function takes a \textit{phantom} argument |x| which is never evaluated. It returns all the fields of all possible constructors of |x|'s type, along with a type representation from |typeOf|. Hence all types can be divided into three sets:

\begin{enumerate}
\item The singleton set containing the type of the target.
\item The set of other types which \textit{may} contain the target type.
\item The set of other types which \textit{do not} contain the target type.
\end{enumerate}

We compute these sets for each type only once, by using a CAF inside the class to store it. The cost of computing them is small. When examining a value, if its type is a member of set 3 we can prune the search. This trick is surprisingly effective. Take for example an operation over |Bool| on the value |(True,"Haskell")|. The SYB approach finds 16 subcomponents, Uniplate touches only 3 subcomponents.

With all these optimisations we can usually perform both queries and transformations faster than SYB. In the benchmarks we range from 4\% worse to 127\% better, with an average of 56\% faster. Full details are presented in \S\ref{secU:results_speed}.


\section{Results and Evaluation}
\label{secU:results}

We evaluate our boilerplate reduction scheme in two ways: firstly by the \textit{conciseness of traversals} using it (i.e. the amount of boilerplate it removes), and secondly by its \textit{runtime performance}. We measure conciseness by counting lexemes -- although we concede that some aspects of concise expression may still be down to personal preference. We give a set of nine example programs, written using Uniplate, SYB and Compos operations. We then compare both the conciseness and the performance of these programs. Other aspects, such as the clarity of expression, are not so easily measured. Readers can make their own assessment based on the full sources we give.

\subsection{Boilerplate Reduction}
\label{secU:results_boilerplate}

As test operations we have taken the first three examples from this chapter, three from the Compos paper \citep{bringert:compos}, and the three given in the SYB paper \citep{lammel:syb} termed the ``Paradise Benchmark''. In all cases the Compos, SYB and Uniplate functions are given an appropriately prefixed name. In some cases, a helper function can be defined in the same way in both SYB and Uniplate; where this is possible we have done so. Type signatures are omitted where the compiler is capable of inferring them. For SYB and Compos we have used definitions from the original authors where available, otherwise we have followed the guidelines and style presented in the corresponding paper.

\subsubsection{Examples from this Chapter}

\begin{exampleany}{from \S\ref{secU:intro} (revisited)}

\ignore\begin{code}
uni_variables x = [y | Var y <- universe x]

syb_variables = everything (++) ([] `mkQ` f)
    where  f (Var y)  = [y]
           f _        = []

com_variables :: Expr a -> [String]
com_variables x = case x of
    Var y -> [y]
    _ -> composOpFold [] (++) com_variables x
\end{code}

Only Compos needs a type signature, due to the use of GADTs. List comprehensions allow for succinct queries in Uniplate.
\end{exampleany}

\begin{examplerevisit}{\ref{exU:zerocount}}

\ignore\begin{code}
uni_zeroCount x = length [() | Div _ (Val 0) <- universe x]

syb_zeroCount = everything (+) (0 `mkQ` f)
    where  f (Div _ (Val 0))  = 1
           f _                = 0

com_zeroCount :: Expr a -> Int
com_zeroCount x = case x of
    Div y (Val 0) -> 1 + com_zeroCount y
    _ -> composOpFold 0 (+) com_zeroCount x
\end{code}

In the Uniplate solution the list of |()| is perhaps inelegant. However, Uniplate is the only scheme that is able to use the standard |length| function: the other two express the operation as a fold. Compos requires additional boilerplate to continue the operation on |Div y|.
\end{examplerevisit}

\begin{examplerevisit}{\ref{exU:simplify}}

\ignore\begin{code}
simp (Sub x y)           = simp $ Add x (Neg y)
simp (Add x y) | x == y  = Mul (Val 2) x
simp x                   = x

uni_simplify = transform simp

syb_simplify = everywhere (mkT simp)

com_simplify :: Expr a -> Expr a
com_simplify x = case x of
    Sub  a b -> com_simplify $ Add (com_simplify a) (Neg (com_simplify b))
    Add  a b -> case  (com_simplify a, com_simplify b) of
                      (a',b')  | a' == b'   -> Mul (Val 2) a'
                               | otherwise  -> Add a' b'
    _ -> composOp com_simplify x
\end{code}

This is a modified version of |simplify| discussed in \S\ref{secU:rewrite_bottom}. The two rules are applied everywhere possible. Compos does not provide a bottom-up transformation, so needs extra boilerplate.
\end{examplerevisit}

\subsubsection{Multi-type examples from the Compos paper}

\begin{figure}
\ignore\begin{code}
data Stm  =  SDecl    Typ Var   | SAss     Var Exp
          |  SBlock   [Stm]     | SReturn  Exp
data Exp  =  EStm  Stm          |  EAdd  Exp Exp
          |  EVar  Var          |  EInt  Int
data Var  =  V String
data Typ  =  T_int              | T_float
\end{code}
\caption{Data type from Compos.}
\label{figU:compos}
\end{figure}

The statement type manipulated by the Compos paper is given in Figure \ref{figU:compos}. The Compos paper translates this type into a GADT, while Uniplate and SYB both accept the definition as supplied.

As the |warnAssign| function from the Compos paper could be implemented much more neatly as a query, rather than a monadic fold, we choose to ignore it. We cover the remaining three functions.

\begin{examplename}{rename}

\ignore\begin{code}
ren (V x) = V ("_" ++ x)

uni_rename = transformBi ren

syb_rename = everywhere (mkT ren)

com_rename :: Tree c -> Tree c
com_rename t = case t of
    V x -> V ("_" ++ x)
    _   -> composOp com_rename t
\end{code}

The Uniplate definition is the shortest, as there is only one constructor in type |Var|. As Compos redefines all constructors in one GADT, it cannot benefit from this knowledge.
\end{examplename}

\begin{examplename}{symbols}

\ignore\begin{code}
uni_symbols x = [(v,t) | SDecl t v <- universeBi x]
\end{code}
\ignore\begin{code}
syb_symbols = everything (++) ([] `mkQ` f)
    where  f (SDecl t v)  = [(v,t)]
           f _            = []

com_symbols :: Tree c -> [(Tree Var, Tree Typ)]
com_symbols x = case x of
    SDecl t v -> [(v,t)]
    _ -> composOpMonoid com_symbols x
\end{code}

Whereas the Compos solution explicitly manages the traversal, the Uniplate solution is able to use the built-in |universeBi| function. The use of lists again benefits Uniplate over SYB.
\end{examplename}

\begin{examplename}{constFold}

\ignore\begin{code}
optimise (EAdd (EInt n) (EInt m)) = EInt (n+m)
optimise x = x

uni_constFold = transformBi optimise

syb_constFold = everywhere (mkT optimise)

com_constFold :: Tree c -> Tree c
com_constFold e = case e of
    EAdd x y -> case  (com_constFold x, com_constFold y) of
                      (EInt n, EInt m) -> EInt (n+m)
                      (x',y') -> EAdd x' y'
    _ -> composOp com_constFold e
\end{code}

The constant-folding operation is a bottom-up transformation, requiring all subexpressions to have been transformed before an enclosing expression is examined. Compos only supports top-down transformations, requiring a small explicit traversal in the middle. Uniplate and SYB both support bottom-up transformations.
\end{examplename}

\subsubsection{The Paradise Benchmark from SYB}

\begin{figure}
\begin{code}
type  Manager   = Employee
type  Name      = String
type  Address   = String
data  Company   = C [Dept]
data  Dept      = D Name Manager [Unit]
data  Unit      = PU Employee | DU Dept
data  Employee  = E Person Salary
data  Person    = P Name Address
data  Salary    = S Integer
\end{code}
\caption{Paradise Benchmark data structure.}
\label{figU:paradise}
\end{figure}

The Paradise benchmark was introduced in the SYB paper \citep{lammel:syb}. The data type is shown in Figure \ref{figU:paradise}. The idea is that this data type represents an XML file, and a Haskell program is being written to perform various operations over it. The Compos paper includes an encoding into a GADT, with tag types for each of the different types.

We have made one alteration to the data type: |Salary| is no longer of type |Float| but of type |Integer|. In various experiments we found that the rounding errors for floating point numbers made different definitions return different results.\footnote{Storing your salary in a non-exact manner is probably not a great idea!} This change is of no consequence to the boilerplate code.

\begin{examplename}{increase}

The first function discussed in the SYB paper is |increase|. This function increases every item of type |Salary| by a given percentage. In order to fit with our modified |Salary| data type, we have chosen to increase all salaries by |k|.

\ignore\begin{code}
incS k (S s) = S (s + k)

uni_increase k = transformBi (incS k)

syb_increase k = everywhere (mkT (incS k))

com_increase :: Integer -> Tree c -> Tree c
com_increase k c = case c of
    S s -> S (s + k)
    _ -> composOp (com_increase k) c
\end{code}

In the Compos solution all constructors belong to the same GADT, so instead of just matching on |S|, all constructors must be examined.
\end{examplename}

\begin{examplename}{incrOne}

The |incrOne| function performs the same operation as |increase|, but only within a named department. The one subtlety is that if the named department has a sub-department with the same name, then the salaries of the sub-department should only be increased once. We are able to reuse the |increase| function from the previous section in all cases.

\ignore\begin{code}
uni_incrOne d k = descendBi f
    where f x@(D n _ _)  | n == d     = uni_increase k x
                         | otherwise  = descend f x
\end{code}
\ignore\begin{code}
syb_incrOne :: Data a => Name -> Integer -> a -> a
syb_incrOne d k x  | isDept d x  = syb_increase k x
                   | otherwise   = gmapT (syb_incrOne d k) x
    where  isDept   d = False `mkQ` isDeptD d
           isDeptD  d (D n _ _) = n == d

com_incrOne :: Name -> Integer -> Tree c -> Tree c
com_incrOne d k x = case x of
    D n _ _ | n == d -> com_increase k x
    _ -> composOp (com_incrOne d k) x
\end{code}

The SYB solution has grown substantially more complex, requiring two different utility functions. In addition |syb_incrOne| now \textit{requires} a type signature. Compos retains the same structure as before, requiring a case to distinguish between the types of constructor. For Uniplate we use |descend| rather than |transform|, to ensure no salaries are incremented twice.
\end{examplename}

\begin{examplename}{salaryBill}

The final function is one which sums all the salaries.

\ignore\begin{code}
uni_salaryBill x = sum [s | S s <- universeBi x]

syb_salaryBill = everything (+) (0 `mkQ` billS)
   where billS (S s) = s

com_salaryBill :: Tree c -> Integer
com_salaryBill x = case x of
    S s -> s
    _ -> composOpFold 0 (+) com_salaryBill x
\end{code}

Here the Uniplate solution wins by being able to use a list comprehension to select the salary value out of a Salary object. The Uniplate class is the only one that is able to use the standard Haskell |sum| function, not requiring an explicit fold.
\end{examplename}

\subsubsection{Uniplate compared to SYB and Compos}

\begin{sidewaystable}
\caption{Table of lexeme counts and runtime performance.}
\label{tabU:uniplate_results}
\vspace{3mm}
\newlength{\maxany}
\settowidth{\maxany}{00.00}
\begin{tabular*}{\textwidth}{@@{}lrrrrrrrrrrrr}
& \makebox[\maxany][r]{simp} & \makebox[\maxany][r]{var} & \makebox[\maxany][r]{zero} & \makebox[\maxany][r]{const} & \makebox[\maxany][r]{ren} & \makebox[\maxany][r]{syms} & \makebox[\maxany][r]{bill} & \makebox[\maxany][r]{incr} & \makebox[\maxany][r]{incr1} & \textbf{Query} & \textbf{Transform} & \makebox[\maxany][r]{\textbf{All}} \\
\textbf{Lexemes} \\
Uniplate   & 40 & 12 & 18 & 27 & 16 & 17 & 13 & 21 & 30 &  60 & 134 & 194 \\
SYB        & 43 & 29 & 29 & 30 & 19 & 34 & 21 & 24 & 56 & 113 & 172 & 285 \\
Compos     & 71 & 30 & 32 & 54 & 27 & 36 & 25 & 33 & 40 & 123 & 225 & 348 \\
\\
\textbf{Performance} \\
Compos             &  1.34 &  1.17 &  1.74 &  1.28 &  1.22 &  1.30 &  2.49 &  1.52 &  1.57 &  1.68 &  1.39 &  1.51 \\
Uniplate Manual    &  1.16 &  1.44 &  2.64 &  1.27 &  1.36 &  1.48 &  2.28 &  1.27 &  1.08 &  1.96 &  1.23 &  1.55 \\
Uniplate Direct    &  1.22 &  1.61 &  3.28 &  1.21 &  1.18 &  1.38 &  2.35 &  1.19 &  1.16 &  2.15 &  1.19 &  1.62 \\
Uniplate Typeable  &  1.43 &  2.09 &  4.81 &  1.42 &  1.37 &  2.63 &  5.86 &  1.53 &  1.53 &  3.85 &  1.46 &  2.52 \\
Uniplate Data      &  2.30 &  4.64 & 12.70 &  1.84 &  1.89 &  3.60 & 10.70 &  2.07 &  1.69 &  7.91 &  1.96 &  4.60 \\
SYB            &  2.21 &  5.88 & 16.62 &  2.30 &  2.13 &  5.56 & 24.29 &  3.12 &  2.35 & 13.09 &  2.42 &  7.16 \\
\\
\end{tabular*}

\textbf{Lexemes} are the number of lexemes for each of the solutions to the test problems using each of Uniplate, SYB and Compos. \textbf{Performance} is expressed as multiples of the run-time for a hand-optimised version not using any traversal library, with lower being better.
\end{sidewaystable}

In order to measure conciseness of expression, we have taken the code for all solutions and counted the number of lexemes -- using the |lex| function provided by Haskell. A table of results is given in Table \ref{tabU:uniplate_results}. The definitions of functions shared between SYB and Uniplate are included in both measurements. For the |incrOne| function we have not included the code for |increase| as well.

The Compos approach requires much more residual boilerplate than Uniplate, particularly for queries, bottom-up transformations and in type signatures. The Compos approach also requires a GADT representation.

Compared with SYB, Uniplate seems much more similar. For queries, Uniplate is able to make use of list comprehensions, which produces shorter code and does not require encoding a manual fold over the items of interest. For transformations, typically both are able to use the same underlying operation, and the difference often boils down to the |mkT| wrappers in SYB.


\subsection{Runtime Overhead}
\label{secU:results_speed}

This section compares the speed of solutions for the nine examples given in the previous section, along with hand-optimised versions, using no boilerplate removal library. We use four |Uniplate| instances, provided by:

\begin{description}
\item[Manual:] These are |Uniplate| and |Biplate| instances written by hand. We have chosen not to use continuation-passing to implement these instances, as it quickly becomes complex!
\item[Direct:] These instances use the direct combinators from \S\ref{secU:implement_playdirect}.
\item[Typeable:] These instances use the |Typeable| combinators from \S\ref{secU:implement_playtypeable}.
\item[Data:] These instances use the SYB |Data| instances directly, as described in \S\ref{secU:implement_playdata}.
\end{description}

For all data types we generate 100 values at random using QuickCheck \citep{quickcheck}. In order to ensure a fair comparison, we define one data type which is the same as the original, and one which is a GADT encoding. All operations take these original data types, transform them into the appropriate structure, apply the operation and then unwrap them. We measure all results as multiples of the time taken for a hand-optimised version. We compiled all programs with GHC 6.6 and -O2 on Windows XP.

\begin{comment}
\begin{figure}
% http://csdl.ics.hawaii.edu/FAQ/chart-ps.html
\includegraphics[scale=0.4]{graph.ps}
\caption{Timing results, relative to Raw.}
\label{figU:graph}
\end{figure}
\end{comment}

The results are presented in Table \ref{tabU:uniplate_results}. Using Manual or Direct instances, Uniplate is roughly the same speed as Compos -- but about 50\% slower than hand-optimised versions. Using the Data instances provided by SYB, we are able to outperform SYB itself! See \S\ref{secU:performance} for details of some of the optimisations used.


\section{Related Work}
\label{secU:related}

The Uniplate library is intended to be a way to remove the boilerplate of traversals from Haskell programs. It is far from the first library to attempt boilerplate removal.

\subsection{The SYB library}
 
The SYB library \citep{lammel:syb} is perhaps the most popular boilerplate removal system in Haskell. One of the reasons for its success is tight integration with the GHC compiler, lowering the barrier to use. We have compared directly against traversals written in SYB in \S\ref{secU:results_boilerplate}, and have also covered how to implement Uniplate in terms of SYB in \S\ref{secU:implement_playdata}. In our experience most operations are shorter and simpler than the equivalents in SYB, and we are able to operate without the extension of rank-2 types. Most of these benefits stem directly from our definition of children as being the children of the same uniform type, contrasting with the SYB approach of all direct children.

The SYB library is, however, more powerful than Uniplate. If you wish to visit values of different type in a single traversal, Uniplate is unsuitable. The |Data| and |Typeable| methods have also been pushed further in successive papers \citep{lammel:syb2,lammel:syb3} -- in directions Uniplate may be unable to go.

\subsection{The Compos library}
 
The Compos library \citep{bringert:compos} is another approach to the removal of boilerplate, requiring GADTs \citep{spj:gadt} along with rank-2 types. The Compos library requires an existing data type to be rewritten as a GADT. The conversion from standard Haskell data structures to GADTs currently presents several problems: they are GHC specific, deriving is not supported on GADTs, and GADTs require explicit type signatures. The Compos approach is also harder to write instances for, having no simple instance generation framework, and no automatic derivation tool (although one could be written). The inner |composOp| operator is very powerful, and indeed we have chosen to replicate it in our library as |descend|. But the Compos library is unable to replicate either |universe| or |transform| from our library.

\subsection{The Stratego tool} 

The Stratego tool \citep{stratego} provides support for generic operations, focusing on both the operations and the strategies for applying them. This approach is performed in an \textit{untyped} language, although a typed representation can be modelled \cite{lammel:typed_generic_strategies}. Rather than being a Haskell library, Stratego implements a domain specific language that can be integrated with Haskell.

\subsection{The Strafunski library}
 
The Strafunski library \citep{strafunski, lammel:polymorphic_symphony} has two aspects: generic transformations and queries for trees of any type; and features to integrate components into a larger programming system. Generic operations are performed using strategy combinators which can define special case behaviour for particular types, along with a default to perform in other situations. The Strafunski library is integrated with Haskell, primarily providing support for generic programming in application areas that involve traversals over large abstract syntax trees.

\subsection{The Applicative library}
 
The Applicative library \citep{mcbride:applicative} works by threading an Applicative operation through a data structure, in a similar way to threading a Monad through the structure. There is additionally a notion of |Traversable| functor, which can be used to provide generic programming. While the Applicative library can be used for generic programming, this task was not its original purpose, and the authors note they have ``barely begun to explore'' its power as a generic toolkit.

\subsection{Generic Programming}

There are a number of other libraries which deal with generic programming, aimed more at writing \textit{type generic} (or \textit{polytypic}) functions, but which can be used for boilerplate removal. The \textit{Haskell generics suite}\footnote{\url{http://darcs.haskell.org/generics/}} showcases several approaches \citep{weirich:replib,hinze:generics_masses,hinze:generic_haskell}.

