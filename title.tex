%include paper.fmt

\title{Transformation and Analysis \\ of Functional Programs}
\author{Neil Mitchell}
\date{\normalsize{
    \vspace{20mm}
    Submitted for the degree of Doctor of Philosophy \\
    \vspace{10mm}
    Department of Computer Science \\
    University of York \\
    \today}}

\maketitle

\setcounter{page}{2}

\chapter*{Abstract}

This thesis deals the transformation and analysis of functional programs. All the work operates over a core lazy functional language, to which Haskell programs can be reduced. We first show how to manipulate such a language in a concise and simple manner, by abstracting over common traversal programs. We then describe how to decrease the execution time of functional programs. Next we describe a transformation which removes functional values from a program. Finally, we describe an analysis to check for safety on first-order programs.

Generic traversals over recursive data structures are often referred to as \textit{boilerplate} code. The definitions of functions involving such traversals may repeat very similar patterns, but with variations for different data types and different functionality. Libraries of operations abstracting away boilerplate code typically rely on elaborate types to make operations generic. Our motivating observation is that \textit{most traversals have value-specific behaviour for just one type}. We present the design of a new library exploiting this assumption. Our library allows concise expression of traversals with competitive performance.

High-level features such as such as higher order functions and lazy evaluation present many challenges for optimising compilers. We report practical experiments using novel variants of \textit{supercompilation}, with special attention to let bindings and the generalisation technique.

We describe an automated transformation which takes a higher-order program, and a produces an equivalent first-order program. Unlike Reynolds style defunctionalisation, it does not introduce any new data types, and the results are more amenable to subsequent analysis operations. Our method cannot always succeed in removing \textit{all} functional values, but in practice it is remarkably successful.

We describe an automated analysis of a first-order functional language to check statically that, despite the possible use of partial (or non-exhaustive) pattern matching, no pattern-match failure can occur.  Our method is an iterative backward analysis using a novel form of pattern-constraint to represent sets of data values. Our analysis tool has been successfully applied to a range of programs, and our techniques seem to scale well.


\tableofcontents
\listoffigures
\listoftables

\chapter*{Acknowledgements}


The first author is a supported by an EPSRC PhD studentship. Thanks to Bj\"{o}rn Bringert, Jules Bean and the anonymous reviewers for feedback on an earlier drafts of this paper; Eric Mertens for helpful ideas; and Stefan O'Rear for work on the Derive tool.

We would like to thank Simon Peyton Jones, Simon Marlow and Tim Chevalier for help understanding the low-level details of GHC, and Peter Jonsson for helpful discussions and presentation suggestions.


\chapter*{Declaration}

All of the research presented in this document has been produced in collaboration with Colin Runciman.

Portions of the material presented in ... appeared previously in the paper Supercompilation Haskell, written with Colin Runciman. This paper was presented to the ..., and is published in the associated proceedings, ....

Some of the material presented in this thesis has previously been published in []. Expect for the above cases and where stated, all of the work contained within this thesis represents the original contribution of the author.

