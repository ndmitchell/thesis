
%include thesis.fmt

\chapter{Background}
\label{chp:background}

In this chapter we introduce the background material and general notations used throughout the rest of this thesis. We start by introducing a Core language in \S\ref{sec:core}, then discuss the semantics of this Core language in \S\ref{sec:semantics}, including its sharing properties in \S\ref{sec:sharing}.

\section{Core Language}
\label{sec:core}

\begin{figure}
\begin{code}
expr  =  v                                          {-" \text{  variable} "-}
      |  c                                          {-" \text{  constructor} "-}
      |  f                                          {-" \text{  function} "-}
      |  x y                                        {-" \text{  application} "-}
      |  \v -> x                                    {-" \text{  lambda abstraction} "-}
      |  let v = x in y                             {-" \text{  let binding} "-}
      |  case x of {p_1 -> y_1 ; ... ; p_n -> y_n}  {-" \text{  case expression} "-}

pat   =  c vs_
\end{code}

Where |v| ranges over variables, |c| ranges over constructors, |f| ranges over functions, |x| and |y| range over expressions and |p| ranges over patterns.
\caption{Core syntax}
\label{fig:core}
\end{figure}

The expression type of our Core language is given in Figure \ref{fig:core}. A program is a mapping of function names to expressions. Our Core language is higher order and lazy, but lacks much of the syntactic sugar found in Haskell. Pattern matching occurs only in case expressions; alternatives match only the top level constructor and are exhaustive, including an |error| alternative if necessary.

We allow a list of variables to appear in a lambda abstraction, or a list of expressions to appear as the second argument of an application. These can be translated away using the following rules:

\begin{code}
x y ys_      => (x y) ys_
\v vs_ -> x  => \v -> (\vs_ -> x)
\end{code}

Some functions are used but lack corresponding definitions in the program. These are defined to be \textit{primitive}. They have some meaning to an underlying runtime system, but are not available for transformation. A primitive function may perform an action such as outputting a character to the screen, or may manipulate primitive numbers such as addition.

The primary difference between our Core language and GHC-Core \cite{ghc_core} is that our Core language is untyped. The Core is generated from well-typed Haskell, and is guaranteed not to fail with a type error. All the work we do could be implemented equally well in a typed Core language, but we prefer to work in an untyped language for simplicity of implementation. For describing data types we use the same notation as Haskell 98. One of the most common data types is the list, which can be defined as:

\begin{code}
data List alpha = Nil | Cons alpha (List alpha)
\end{code}

A list is either an empty list, or a cons cell which contains an element of the list type and the tail of the list. For example the list of 1,2,3 would be written |(Cons 1 (Cons 2 (Cons 3 Nil)))|. We allow the syntactic sugar of representing |Cons| as a right-associative infix application of |(:)| and |Nil| as |[]| -- allowing us to write |(1:2:3:[])|. We also permit |[1,2,3]|.

\subsection{Generating Core}

In order to generate our Core language from the full Haskell language, we use the Yhc compiler \cite{yhc}, a fork of nhc \cite{nhc}.

The internal Core language of Yhc is PosLambda -- a simple variant of lambda calculus without types, but with source position information. Yhc works by applying basic desugaring transformations, without optimisation. This simplicity ensures the generated PosLambda is close to the original Haskell in its structure. Each top-level function in a source file maps to a top-level function in the generated PosLambda, retaining the same name. However, PosLambda has constructs that have no direct representation in Haskell. For example, there is a FatBar construct \cite{spj:implementation}, used for compiling pattern matches which require fall through behaviour. We have therefore introduced a new Core language to Yhc, to which PosLambda can easily be translated \cite{me:yhc_core}.

The Yhc compiler can generate the Core for a single source file. Yhc can also link in all definitions from all required libraries, producing a single Core file representing a whole program. All function and constructor names are fully qualified, so the linking process simply involves merging the list of functions from each required Core file.

In the process of generating a Core file, Yhc performs several transformations. Haskell's type classes are removed using the dictionary transformation (see \S\ref{sec:dictionary_transformation}). All local functions are lambda lifted, leaving only top-level functions -- ensuring Yhc generated Core does \textit{not} contain any lambda expressions. All constructor applications and primitive applications are fully saturated.


\subsection{The Dictionary Transformation}
\label{sec:dictionary_transformation}

Most transformations in Yhc operate within a single function definition. The only phases which require information about more than one function are type checking and the transformation used to implement type classes \citep{wadler:type_classes}. The dictionary transformation introduces tuples (or \textit{dictionaries}) of methods passed as additional arguments to class-polymorphic functions. Haskell also allows subclassing. For example, |Ord| requires |Eq| for the same type. In such cases the dictionary transformation generates a nested tuple: the |Eq| dictionary is a component of the |Ord| dictionary.

\begin{example}
\label{ex:dictionary}
\begin{code}
f :: Eq alpha => alpha -> alpha -> Bool
f x y = x == y || x /= y
\end{code}

\noindent is translated by Yhc into

\begin{code}
f :: (alpha -> alpha -> Bool, alpha -> alpha -> Bool) -> alpha -> alpha -> Bool
f dict x y = (||) (((==) dict) x y) (((/=) dict) x y)

(==) (a,b) = a
(/=) (a,b) = b
\end{code}

The |Eq| class is implemented as two selector functions, |(==)| and |(/=)|, acting on a method table. For different types of |alpha|, different method tables are provided.
\end{example}

The dictionary transformation is a global transformation. In Example \ref{ex:dictionary} the |Eq| context in |f| not only requires a dictionary to be accepted by |f|; it requires all the callers of |f| to pass a dictionary as first argument. There are alternative approaches to implementing type classes, such as \citet{jones:dictionary_free}, which does not create a tuple of higher order functions. We use the dictionary transformation for simplicity, as it is already implemented within Yhc.

\subsection{Operations on Core}

There are several operations that can be defined on our Core expressions type. We present some of the most useful, which are used later on.

\subsubsection{Substitution}

We define |e[x / y]| to be the capture free substitution of the variable |x| for the expression |y| within the expression |e|. We define |e[x_1,...,x_n / y_1,...,y_n]| to be the simultaneous substitution of each variable |x_i| for each expression |y_i| in |e|.

\begin{example}
\begin{code}
(v + 1)[v / 2]               => 2 + 1
(let v = 3 in v + 1)[v / 2]  => let v = 3 in v + 1
\end{code}
\end{example}

\subsubsection{Variable Classification}

\begin{figure}
\begin{code}
fv :: Expr -> [FreeVar]
fv (v                ) = [v]
fv (c                ) = []
fv (f                ) = []
fv (x ys_            ) = fv x `union` unions (map fv ys_)
fv (\vs_ -> x        ) = fv x \\ vs_
fv (let v = x in y   ) = fv x `union` (fv y \\ v)
fv (case x of alts_  ) = fv x `union` unions (map f alts)
    where f (c vs_ -> y) = fv y \\ vs_
\end{code}
\caption{Free variables of an expression.}
\label{fig:free_variables}
\end{figure}

The variables in the patterns of case expressions, the arguments of lambda abstractions and the bindings of let expressions are \textit{bound}; all other variables are \textit{free}. The set of free variables of an expression |e| is denoted by |fv e|, and can be computed using the function in Figure \ref{fig:free_variables}. Within a function definition all variables must be bound.

In order to avoid accidental variable name clashes while performing transformations, we demand that all variables within a program are unique. All transformations may assume this invariant, and afterwards any repeated bound variables can be assigned fresh names.

\begin{comment}
\subsubsection{The |split| operation}

\begin{figure}
\begin{tabular}{rcl}
|split(v)| & |=| & |(v, [])| \\
|split(c)| & |=| & |(c, [])| \\
|split(f)| & |=| & |(f, [])| \\
|split(x ys_)| & |=| & |(bullet {-"\text{ } \overline{\bullet} "-}, x:ys_)| \\
|split(\vs_ -> x)| & |=| & |(\vs_ -> bullet, x)| \\
|split(let v = x in y)| & |=| & |(let v = bullet in bullet, [x,y])| \\
|split(case x of {p_1 \! -> \! y_1 ; ... ; p_n \! -> \! y_n})| & |=| & |(case {-"\hspace{-1mm}"-} bullet {-"\hspace{-1mm}"-} of {p_1 \! -> \! bullet ; ... ; p_n \! -> \! bullet}, [x, y_1, ... ,y_n])|
\end{tabular}
\caption{The |split| function, returning a spine and all subexpressions.}
\label{fig:split}
\end{figure}

We define the |split| function in Figure \ref{fig:split}, which splits an expression into a pair of its spine and its immediate subexpressions. The $\bullet$ markers in the spine indicate the positions from which subexpressions have been removed. We define the |join| operation to be the inverse of |split|, taking a spine and a list of expressions, and producing an expression.
\end{comment}


\section{Semantics}

We first augment the language with $\bot$, then we can follow much the same pattern as \cite{hammond:semantics}. We define residual forms to be |c \< ... \>|, |\v -> r| and $\bot$.

\newcommand{\sem}[2]{\[\begin{array}{c} #1 \\ \hline \vspace{-1em} \\ #2 \end{array}\]}
\newcommand{\semm}[1]{\[\begin{array}{c} #1 \end{array}\]}

\begin{figure}
\sem{|Gamma(v) = \< Gamma', v' \>| \\
     |Gamma' ||- v' => r|}
    {|Gamma ||- v => r|}

\semm{|Gamma ||- c => c \< \>|}

\sem{|_F(f) = f'| \\
     |Gamma ||- f' => r|}
    {|Gamma ||- f => r|}

\sem{|Gamma ||- x => undefined|}
    {|Gamma ||- x y => undefined|}

\sem{|Gamma ||- x => c \< vs_ \>| \\
     |Gamma ||- y => y'|}
    {|Gamma ||- x y => c \< vs_ y' \>|}

\sem{|Gamma ||- x => \v -> x'| \\
     |Gamma{v = \< Gamma, r' \>} ||- x' => r|}
    {|Gamma ||- x y => r|}

\sem{|Gamma ||- x => r|}
    {|Gamma ||- \v -> x => \v -> r|}

\sem{|Gamma{v = \< Gamma, x \>} ||- y => r|}
    {|Gamma ||- let v = x in y => r|}

\sem{|Gamma ||- x => c \< xs_ \>| \\
     |Gamma{vs_ = \< Gamma, xs \>} ||- y => r|}
    {|Gamma ||- case x of {... ; c vs_ -> y ; ...} => r|}

\sem{|Gamma ||- x => undefined|}
    {|Gamma ||- case x of alts_ => undefined|}
\caption{Semantics of Core.}
\label{fig:semantics}
\end{figure}

Our Core language is defined to be lazy.

We define the semantics by the rules:

A one-step reduction


\subsection{Simplification Rules}

\begin{figure}
\begin{code}
case (case x of {p_1 -> y_1 ; ... ; p_n -> y_n}) of alts_
    => case x of  {  p_1  -> case y_1 of alts_
                  ;  ...
                  ;  p_n  -> case y_n of alts_ }

case c xs_ of {... ; c vs_ -> y ; ...}
    => y[vs_/xs_]

case (let v = x in y) of alts_
    => let v = x in case y of alts_

(let v = x in y) z
    => let v = x in y z

(case x of {p_1 -> y_1 ; ... ; p_n -> y_n}) z
    => case x of {p_1 -> y_1 z ; ... ; p_n -> y_n z}

(\v -> x) y
    => let v = y in x

(x xs_) ys_
    => x xs_ ys_

let v = x in (case y of {p_1 -> y_1 ; ... ; p_n -> y_n})
    => case y of  {  p_1  -> let v = x in y_1
                  ;  ...
                  ;  p_n  -> let v = x in y_n}
    where v {-" \hbox{is not used in } "-} y

let v = x in y
    => y[v/x]
    where x {-" \hbox{is used once in } "-} y
\end{code}
\caption{Simplification rules.}
\label{fig:simplify}
\end{figure}



\section{Sharing}

\subsection{Let bindings}



\subsection{Recursive let bindings}

In the standard Haskell language, let bindings can be \textit{recursive}. To take an example:

\begin{code}
repeat x = let xs = x : xs
           in xs
\end{code}

Here the variable |xs| is both defined and introduced in the binding. Given the application |repeat 1|, regardless of how much of the list is examined, we will only ever create one single cons cell. This construct effectively ties a loop in the memory.

Our Core language does not allow recursive let bindings, for reasons of simplicity. They can be translated away easily:

\begin{enumerate}
\item For each recursive let binding, assign it a unique name.
\item Take all the recursive variables
\end{enumerate}

Applying this to our example from before:

\begin{code}
repeat x = f x

f x =  let r = x : f x
       in r
\end{code}

We have lost the sharing, but in this case we occur only a constant time overhead compared to the original value. Because we are working in a referentially transparent language, to examine the $n$th element of the list generated by |repeat| will take at least $O(n)$. To generate those elements using the first algorithm will take $O(1)$, but using the second version will take $O(n)$. If the elements are not examined they will not be required due to lazy evaluation, therefore it is impossible to harm.

It is possible to engineer examples where the recursive let removal does cause a serious slowdown:



\subsection{Constant Applicative Form}


A CAF (constant applicative form) is a top level definition of zero arity. In Haskell, CAFs are computed at most once per program run, and retained as long as references to them remain. Consider the program:

\begin{code}
caf = expensive

main = caf + caf
\end{code}


\subsection{Common Subexpression Elimination}

\cite{chitil:cse}

