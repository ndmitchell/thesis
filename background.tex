
%include thesis.fmt

\chapter{Background}
\label{chp:background}

In this chapter we introduce the background material and general notations that are used throughout the rest of this thesis. We start by introducing a Core language in \S\ref{sec:core}, then discuss the semantics of this Core language in \S\ref{sec:semantics}, including its sharing properties in \S\ref{sec:sharing}.

\section{Core Language}

\label{sec:core}

\begin{fig}
\begin{code}
expr  =  v                                          {-" \text{  variable} "-}
      |  c                                          {-" \text{  constructor} "-}
      |  f                                          {-" \text{  function} "-}
      |  x ys_                                      {-" \text{  application} "-}
      |  \vs_ -> x                                  {-" \text{  lambda abstraction} "-}
      |  let v = x in y                             {-" \text{  let binding} "-}
      |  case x of {p_1 -> y_1 ; ... ; p_n -> y_n}  {-" \text{  case expression} "-}

pat   =  c vs_
\end{code}

Where |v| ranges over variables, |c| ranges over constructors, |f| ranges over functions, |x| and |y| range over expressions and |p| ranges over patterns.
\bigskip
\figend
\caption{Core syntax}
\label{fig:core}
\end{fig}

The expression type is given in Figure \ref{fig:core}. A program is a mapping of function names to expressions. Our Core language is higher order and lazy, but lacks much of the syntactic sugar found in Haskell. Pattern matching occurs only in case expressions, and all case expressions are exhaustive. All names are fully qualified. Haskell's type classes have been removed using the dictionary transformation \cite{wadler:type_classes}.

All names are fully qualified. Haskell's type classes have been removed (see \S\ref{sec:dict}). Only top-level functions remain; all local functions have been lambda lifted. All constructor applications are fully saturated. Pattern matching occurs only in case expressions; alternatives match only the top level constructor and are exhaustive, including an \C{error} alternative if necessary.
 
In order to avoid accidental variable name clashes while performing transformations, we demand that all variables within a program are unique. All transformations may assume this invariant, and must maintain it.

\subsection{Generating Core}

Our supercompiler uses the Yhc-Core language \cite{me:yhc_core}.

The Yhc compiler, a fork of nhc \cite{nhc}, can output Core files. Yhc can also link in all definitions from all required libraries, producing a single Core file representing a whole program.

The primary difference between Yhc-Core and GHC-Core \cite{ghc_core} is that Yhc-Core is untyped. The Core is generated from well-typed Haskell, and is guaranteed not to fail with a type error. All the transformations could be implemented equally well in a typed Core language, but we prefer to work in an untyped language for simplicity of implementation.

The full Haskell language is unwieldy for analysis. As noted in \S\ref{sec:core}, analysis is performed instead on a simplified language, a core to which other Haskell programs can be reduced.

-- a simple variant of lambda calculus without types, but with source position information. Yhc works by applying basic desugaring transformations, without optimisation. This simplicity ensures the generated PosLambda is close to the original Haskell in its structure. Each top-level function in a source file maps to a top-level function in the generated PosLambda, retaining the same name.

However, PosLambda has constructs that have no direct representation in Haskell. For example, there is a FatBar construct \cite{spj:implementation}, used for compiling pattern matches which require fall through behaviour. The PosLambda language

To generate core representations of programs, it is natural to start with a full Haskell compiler, and we chose Yhc \citep{me:yhc_core}, a fork of nhc \citep{nhc}. The core language of Yhc, PosLambda, was intended only as an internal representation, and exposes certain details that are specific to the compiler. We have therefore introduced a new Core language to Yhc, to which PosLambda can easily be translated.


\subsection{The Dictionary Transformation}
\label{sec:dict}

Most transformations in Yhc operate within a single function definition. The only phases which require information about more than one function are type checking and the transformation used to implement type classes \citep{wadler:type_classes}. The dictionary transformation introduces tuples (or \textit{dictionaries}) of methods passed as additional arguments to class-polymorphic functions. Haskell also allows subclassing. For example, \C{Ord} requires \C{Eq} for the same type. In such cases the dictionary transformation generates a nested tuple: the \C{Eq} dictionary is a component of the \C{Ord} dictionary.

\begin{example}
\nopagebreak
\ignore\begin{code}
f :: Eq alpha => alpha -> alpha -> Bool
f x y = x == y || x /= y
\end{code}

\noindent is translated by Yhc into

\begin{code}
f :: (alpha -> alpha -> Bool, alpha -> alpha -> Bool) -> alpha -> alpha -> Bool
f dict x y = (||) (((==) dict) x y) (((/=) dict) x y)

(==) (a,b) = a
(/=) (a,b) = b
\end{code}

The |Eq| class is implemented as two selector functions, |(==)| and |(/=)|, acting on a method table. For different types of |alpha|, different method tables are provided.
\end{example}

The dictionary transformation is a global transformation. In Example \lastexample{} the \C{Eq} context in \C{f} not only requires a dictionary to be accepted by \C{f}; it requires all the callers of \C{f} to pass a dictionary as first argument. An alternative approach to implementing type classes, given in \citet{jones:dictionary_free}, does not rely on higher order functions. Although this approach might suit \catch{} better, we re-used the method already implemented in Yhc.

\subsection{Operations on Core}

\subsubsection{Substitution}

Capture free parallel substitution.

\subsubsection{Variable Classification}

Bound, free etc.


\subsubsection{The |split| operation}

\begin{fig}
\vspace{2mm}
\begin{tabular}{rcl}
|split(v)| & |=| & |(v, [])| \\
|split(c)| & |=| & |(c, [])| \\
|split(f)| & |=| & |(f, [])| \\
|split(x ys_)| & |=| & |(bullet {-"\text{ } \overline{\bullet} "-}, x:ys_)| \\
|split(\vs_ -> x)| & |=| & |(\vs_ -> bullet, x)| \\
|split(let v = x in y)| & |=| & |(let v = bullet in bullet, [x,y])| \\
|split(case x of {p_1 \! -> \! y_1 ; ... ; p_n \! -> \! y_n})| & |=| & |(case {-"\hspace{-1mm}"-} bullet {-"\hspace{-1mm}"-} of {p_1 \! -> \! bullet ; ... ; p_n \! -> \! bullet}, [x, y_1, ... ,y_n])|
\end{tabular}
\vspace{2mm}
\figend
\caption{The |split| function, returning a spine and all subexpressions.}
\label{fig:split}
\end{fig}

We define the |split| function in Figure \ref{fig:split}, which splits an expression into a pair of its spine and its immediate subexpressions. The $\bullet$ markers in the spine indicate the positions from which subexpressions have been removed. We define the |join| operation to be the inverse of |split|, taking a spine and a list of expressions, and producing an expression.



\section{Sharing}

\subsection{Recursive let bindings}

In the standard Haskell language, let bindings can be \textit{recursive}. To take an example:

\begin{code}
repeat x = let xs = x : xs
           in xs
\end{code}

Here the variable |xs| is both defined and introduced in the binding. Given the application |repeat 1|, regardless of how much of the list is examined, we will only ever create one single cons cell. This construct effectively ties a loop in the memory.

Our Core language does not allow recursive let bindings, for reasons of simplicity. They can be translated away easily:

\begin{enumerate}
\item For each recursive let binding, assign it a unique name.
\item Take all the recursive variables
\end{enumerate}

Applying this to our example from before:

\begin{code}
repeat x = f x

f x =  let r = x : f x
       in r
\end{code}

We have lost the sharing, but in this case we occur only a constant time overhead compared to the original value. Because we are working in a referentially transparent language, to examine the $n$th element of the list generated by |repeat| will take at least $O(n)$. To generate those elements using the first algorithm will take $O(1)$, but using the second version will take $O(n)$. If the elements are not examined they will not be required due to lazy evaluation, therefore it is impossible to harm.

It is possible to engineer examples where the recursive let removal does cause a serious slowdown:



\subsection{Constant Applicative Form}



\section{Semantics}

Our Core language is defined to be lazy.

We define the semantics by the rules:

A one-step reduction 


\subsection{Simplification Rules}

\begin{fig}
\begin{code}
case (case x of {p_1 -> y_1 ; ... ; p_n -> y_n}) of alts_
    => case x of  {  p_1  -> case y_1 of alts_
                  ;  ...
                  ;  p_n  -> case y_n of alts_ }

case c xs_ of {... ; c vs_ -> y ; ...}
    => y[vs_/xs_]

case (let v = x in y) of alts_
    => let v = x in case y of alts_

(let v = x in y) z
    => let v = x in y z

(case x of {p_1 -> y_1 ; ... ; p_n -> y_n}) z
    => case x of {p_1 -> y_1 z ; ... ; p_n -> y_n z}

(\v -> x) y
    => let v = y in x

let v = x in (case y of {p_1 -> y_1 ; ... ; p_n -> y_n})
    => case y of  {  p_1  -> let v = x in y_1
                  ;  ...
                  ;  p_n  -> let v = x in y_n}
    where v {-" \hbox{is not used in } "-} y

let v = x in y
    => y[v/x]
    where x {-" \hbox{is used once in } "-} y
\end{code}
\figend
\caption{Simplification rules.}
\label{fig:simplify}
\end{fig}


